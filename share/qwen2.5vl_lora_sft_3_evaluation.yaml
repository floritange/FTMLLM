### model
model_name_or_path: /data/huggingface/hub/models--Qwen--Qwen2.5-VL-32B-Instruct/snapshots/6bcf1c9155874e6961bcf82792681b4f4421d2f7   #配置model路径，回到最开始3e那个目录去copy路径
adapter_name_or_path: results/qwen2.5_vl_lora_sft_dev
trust_remote_code: true
do_predict: true
predict_with_generate: true
flash_attn: auto


stage: sft
template: qwen2_vl


### method
finetuning_type: lora
preprocessing_num_workers: 16
# bf16: true
# quantization_method: hqq
# quantization_bit: 4
# double_quantization: true


### dataset
eval_dataset: mllm_demo  # dataset_info.json配置的数据集名字
dataset_dir: LLaMA-Factory/data  # dataset_info.json所在文件夹
cutoff_len: 2048
max_samples: 100000
per_device_eval_batch_size: 1


### output
output_dir: results/qwen2.5_vl_lora_sft_dev_eval_test1
max_new_tokens: 512
top_p: 0.7
temperature: 0.95