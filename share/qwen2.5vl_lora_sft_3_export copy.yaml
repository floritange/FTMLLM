### Note: DO NOT use quantized model or quantization_bit when merging lora adapters

### model
model_name_or_path: /data/huggingface/hub/models--Qwen--Qwen2.5-VL-32B-Instruct/snapshots/6bcf1c9155874e6961bcf82792681b4f4421d2f7
adapter_name_or_path: results/qwen2.5_vl_lora_sft_dev
template: qwen2_vl
trust_remote_code: true

### export
export_dir: results/export/qwen2.5_vl_lora_sft_dev
export_size: 5
export_device: cpu
export_legacy_format: false